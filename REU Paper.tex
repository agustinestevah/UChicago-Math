
\documentclass[openany, amssymb, psamsfonts]{amsart}
\usepackage{mathrsfs,comment}
\usepackage[usenames,dvipsnames]{color}
\usepackage[normalem]{ulem}
\usepackage{url}
\usepackage[all,arc,2cell]{xy}
\UseAllTwocells
\usepackage{enumerate}
%%% hyperref stuff is taken from AGT style file
\usepackage{hyperref}  
\hypersetup{%
  bookmarksnumbered=true,%
  bookmarks=true,%
  colorlinks=true,%
  linkcolor=blue,%
  citecolor=blue,%
  filecolor=blue,%
  menucolor=blue,%
  pagecolor=blue,%
  urlcolor=blue,%
  pdfnewwindow=true,%
  pdfstartview=FitBH}   
  
\let\fullref\autoref
%
%  \autoref is very crude.  It uses counters to distinguish environments
%  so that if say {lemma} uses the {theorem} counter, then autrorefs
%  which should come out Lemma X.Y in fact come out Theorem X.Y.  To
%  correct this give each its own counter eg:
%                 \newtheorem{theorem}{Theorem}[section]
%                 \newtheorem{lemma}{Lemma}[section]
%  and then equate the counters by commands like:
%                 \makeatletter
%                   \let\c@lemma\c@theorem
%                  \makeatother
%
%  To work correctly the environment name must have a corrresponding 
%  \XXXautorefname defined.  The following command does the job:
%
\def\makeautorefname#1#2{\expandafter\def\csname#1autorefname\endcsname{#2}}
%
%  Some standard autorefnames.  If the environment name for an autoref 
%  you need is not listed below, add a similar line to your TeX file:
%  
%\makeautorefname{equation}{Equation}%
\def\equationautorefname~#1\null{(#1)\null}
\makeautorefname{footnote}{footnote}%
\makeautorefname{item}{item}%
\makeautorefname{figure}{Figure}%
\makeautorefname{table}{Table}%
\makeautorefname{part}{Part}%
\makeautorefname{appendix}{Appendix}%
\makeautorefname{chapter}{Chapter}%
\makeautorefname{section}{Section}%
\makeautorefname{subsection}{Section}%
\makeautorefname{subsubsection}{Section}%
\makeautorefname{theorem}{Theorem}%
\makeautorefname{thm}{Theorem}%
\makeautorefname{cor}{Corollary}%
\makeautorefname{lem}{Lemma}%
\makeautorefname{prop}{Proposition}%
\makeautorefname{pro}{Property}
\makeautorefname{conj}{Conjecture}%
\makeautorefname{defn}{Definition}%
\makeautorefname{notn}{Notation}
\makeautorefname{notns}{Notations}
\makeautorefname{rem}{Remark}%
\makeautorefname{quest}{Question}%
\makeautorefname{exmp}{Example}%
\makeautorefname{ax}{Axiom}%
\makeautorefname{claim}{Claim}%
\makeautorefname{ass}{Assumption}%
\makeautorefname{asss}{Assumptions}%
\makeautorefname{con}{Construction}%
\makeautorefname{prob}{Problem}%
\makeautorefname{warn}{Warning}%
\makeautorefname{obs}{Observation}%
\makeautorefname{conv}{Convention}%


%
%                  *** End of hyperref stuff ***

%theoremstyle{plain} --- default
\newtheorem{thm}{Theorem}[section]
\newtheorem{cor}{Corollary}[section]
\newtheorem{prop}{Proposition}[section]
\newtheorem{lem}{Lemma}[section]
\newtheorem{prob}{Problem}[section]
\newtheorem{conj}{Conjecture}[section]
%\newtheorem{ass}{Assumption}[section]
%\newtheorem{asses}{Assumptions}[section]

\theoremstyle{definition}
\newtheorem{defn}{Definition}[section]
\newtheorem{ass}{Assumption}[section]
\newtheorem{asss}{Assumptions}[section]
\newtheorem{ax}{Axiom}[section]
\newtheorem{con}{Construction}[section]
\newtheorem{exmp}{Example}[section]
\newtheorem{notn}{Notation}[section]
\newtheorem{notns}{Notations}[section]
\newtheorem{pro}{Property}[section]
\newtheorem{quest}{Question}[section]
\newtheorem{rem}{Remark}[section]
\newtheorem{warn}{Warning}[section]
\newtheorem{sch}{Scholium}[section]
\newtheorem{obs}{Observation}[section]
\newtheorem{conv}{Convention}[section]

%%%% hack to get fullref working correctly
\makeatletter
\let\c@obs=\c@thm
\let\c@cor=\c@thm
\let\c@prop=\c@thm
\let\c@lem=\c@thm
\let\c@prob=\c@thm
\let\c@con=\c@thm
\let\c@conj=\c@thm
\let\c@defn=\c@thm
\let\c@notn=\c@thm
\let\c@notns=\c@thm
\let\c@exmp=\c@thm
\let\c@ax=\c@thm
\let\c@pro=\c@thm
\let\c@ass=\c@thm
\let\c@warn=\c@thm
\let\c@rem=\c@thm
\let\c@sch=\c@thm
\let\c@equation\c@thm
\numberwithin{equation}{section}

\newcommand{\bA}{\mathbf{A}}
\newcommand{\bB}{\mathbf{B}}
\newcommand{\bC}{\mathbf{C}}
\newcommand{\bD}{\mathbf{D}}
\newcommand{\bE}{\mathbf{E}}
\newcommand{\bF}{\mathbf{F}}
\newcommand{\bG}{\mathbf{G}}
\newcommand{\bH}{\mathbf{H}}
\newcommand{\bI}{\mathbf{I}}
\newcommand{\bJ}{\mathbf{J}}
\newcommand{\bK}{\mathbf{K}}
\newcommand{\bL}{\mathbf{L}}
\newcommand{\bM}{\mathbf{M}}
\newcommand{\bN}{\mathbf{N}}
\newcommand{\bO}{\mathbf{O}}
\newcommand{\bP}{\mathbf{P}}
\newcommand{\bQ}{\mathbf{Q}}
\newcommand{\bR}{\mathbf{R}}
\newcommand{\bS}{\mathbf{S}}
\newcommand{\bT}{\mathbf{T}}
\newcommand{\bU}{\mathbf{U}}
\newcommand{\bV}{\mathbf{V}}
\newcommand{\bW}{\mathbf{W}}
\newcommand{\bX}{\mathbf{X}}
\newcommand{\bY}{\mathbf{Y}}
\newcommand{\bZ}{\mathbf{Z}}

%% blackboard bold math capitals
\newcommand{\bbA}{\mathbb{A}}
\newcommand{\bbB}{\mathbb{B}}
\newcommand{\bbC}{\mathbb{C}}
\newcommand{\bbD}{\mathbb{D}}
\newcommand{\bbE}{\mathbb{E}}
\newcommand{\bbF}{\mathbb{F}}
\newcommand{\bbG}{\mathbb{G}}
\newcommand{\bbH}{\mathbb{H}}
\newcommand{\bbI}{\mathbb{I}}
\newcommand{\bbJ}{\mathbb{J}}
\newcommand{\bbK}{\mathbb{K}}
\newcommand{\bbL}{\mathbb{L}}
\newcommand{\bbM}{\mathbb{M}}
\newcommand{\bbN}{\mathbb{N}}
\newcommand{\bbO}{\mathbb{O}}
\newcommand{\bbP}{\mathbb{P}}
\newcommand{\bbQ}{\mathbb{Q}}
\newcommand{\bbR}{\mathbb{R}}
\newcommand{\bbS}{\mathbb{S}}
\newcommand{\bbT}{\mathbb{T}}
\newcommand{\bbU}{\mathbb{U}}
\newcommand{\bbV}{\mathbb{V}}
\newcommand{\bbW}{\mathbb{W}}
\newcommand{\bbX}{\mathbb{X}}
\newcommand{\bbY}{\mathbb{Y}}
\newcommand{\bbZ}{\mathbb{Z}}

%% script math capitals
\newcommand{\sA}{\mathscr{A}}
\newcommand{\sB}{\mathscr{B}}
\newcommand{\sC}{\mathscr{C}}
\newcommand{\sD}{\mathscr{D}}
\newcommand{\sE}{\mathscr{E}}
\newcommand{\sF}{\mathscr{F}}
\newcommand{\sG}{\mathscr{G}}
\newcommand{\sH}{\mathscr{H}}
\newcommand{\sI}{\mathscr{I}}
\newcommand{\sJ}{\mathscr{J}}
\newcommand{\sK}{\mathscr{K}}
\newcommand{\sL}{\mathscr{L}}
\newcommand{\sM}{\mathscr{M}}
\newcommand{\sN}{\mathscr{N}}
\newcommand{\sO}{\mathscr{O}}
\newcommand{\sP}{\mathscr{P}}
\newcommand{\sQ}{\mathscr{Q}}
\newcommand{\sR}{\mathscr{R}}
\newcommand{\sS}{\mathscr{S}}
\newcommand{\sT}{\mathscr{T}}
\newcommand{\sU}{\mathscr{U}}
\newcommand{\sV}{\mathscr{V}}
\newcommand{\sW}{\mathscr{W}}
\newcommand{\sX}{\mathscr{X}}
\newcommand{\sY}{\mathscr{Y}}
\newcommand{\sZ}{\mathscr{Z}}
\newcommand{\dd}{\mathrm{d}}
\newcommand{\Var}{\text{Var}}

\renewcommand{\emptyset}{\O}

\newcommand{\abs}[1]{\lvert #1 \rvert}
\newcommand{\norm}[1]{\lVert #1 \rVert}
\newcommand{\sm}{\setminus}


\newcommand{\sarr}{\rightarrow}
\newcommand{\arr}{\longrightarrow}

\makeatother

\bibliographystyle{plain}

%--------Meta Data: Fill in your info------
\title{Working Title}

\author{Agust√çn Esteva}

\date{AUGUST 28, 2024}

\begin{document}

\begin{abstract}

This expository paper develops the theory behind stochastic calculus, with an emphasis placed on a measure-theoretic derivation of the Black-Scholes-Merton equation. 
The paper includes proofs for the existence of Brownian motion, as well as some of its properties, Martingale properties, the Girsanov Theorem, the Ito-Doeblin formula, and the BSM equation. 
\end{abstract}

\maketitle

\tableofcontents
\section{Introduction}
A \textit{stochastic process} is a sequence of random variables who's values are revealed through time. The 

\subsection{Definitions}
For the entirety of the paper, we adopt the following conventions: capital letters, such as $X,Y,Z,$ are random variables; 
\begin{defn}
A \textit{$\sigma-$algebra} $\mathcal{F}$ is a collection of subsets of $X$ such that
\begin{enumerate}
    \item $\emptyset \in \mathcal{F};$
    \item If $E \in \mathcal{F},$ then $E^c\in \mathcal{F};$
    \item If $E_1, E_2, \dots$ are countable, then $\displaystyle\bigcup_{i=1}^\infty E_i$ are in $\mathcal{F}.$
\end{enumerate}
\end{defn}

\begin{defn}
A \textit{measure} on $(X, \mathcal{F})$ is a function $\mu: \mathcal{F}\to [0,\infty)$ such that:
\begin{enumerate}
    \item $\mu(\emptyset) = 0.$
    \item If $E_1, E_2, \dots$ are countable and pairwise disjoint, then 
    \[\mu(\bigcup_{i=1}^\infty E_i) = \sum_{i=1}^\infty \mu(E_i)\]
\end{enumerate}
\end{defn}
We define a \textit{probability measure} $\bbP$ as a measure on a sample space $\Omega$ of outcomes with the added condition that $\bbP(\Omega) =1.$
\textcolor{red}{sigma algebra generation}

\begin{defn}
A \textit{probability space} $(\Omega, \mathcal{F}, \mathbb{P})$ is a triple where $\Omega,$ an arbitrary set, $\mathcal{F}$ is a $\sigma-$algebra of $\Omega$ containing events, and $\mathbb{P}$ is the probability measure on $(\Omega, \mathcal{F}).$
\end{defn}
For the rest of the paper, it is understood, but not always stated, that we are always acting within a probability space. 

\begin{defn}
A \textit{filtration} $\{\mathcal{F}_t\}_{t\in \mathbb{T}}$ of $(\Omega, \mathcal{F}),$ where $\mathbb{T}$ is the time index set, is a sequence of $\sigma-$algebras, $\mathcal{F}_t\subseteq \mathcal{F}$ such that if $s<t,$ then $\mathcal{F}_t\subseteq \mathcal{F}.$
\end{defn}


Thus, we think of a filtration as an increasing sequence of the information contained in the random variables. 

\begin{defn}We say a process $X_t$ is \textit{adapted} to a filtration $\{\mathcal{F}_t\}_{t\in \bbT}$ if $X_t$ is $\mathcal{F}_t-$measurable for each $t.$
\end{defn}

\begin{defn}A measure $\nu$ is said to be \textit{absolutely continuous} with respect to a measure if whenever $\mu(E) = 0,$ then $\nu(E) =0.$ We write this as $\nu\ll\mu.$
\end{defn}

\begin{defn}
Stopping time.
\end{defn}

\begin{lem}
(Chebyshev's Inequality) If $1\leq p < \infty,$ then for any $\lambda>0,$ we have that
\[\bbP\{|X|\geq \lambda\}\leq \frac{\bbE[|X|^p]}{\lambda^p}\]
\end{lem}
\begin{proof} %IIT
Define $A := \{\omega \in \Omega  ; |X(\omega)|\geq \lambda\},$ then 
\[\bbE[|X|^p] = \int_\Omega |X|^p \dd \bbP \geq \int_A |X|^p\geq \lambda^p \int_A\dd \bbP = \bbP\{A\}\]
\end{proof}

For the Borel-Cantelli lemma, we first need a definition.
\begin{defn}
Suppose we have $(\Omega, \mathcal{F}, \bbP)$ as our probability space, and $\{A_n\}$ is a sequence of events where $A_n \in \mathcal{F}$ for all $n.$ We define $(A_n$ i.o$),$  or, \textit{$A_n$ infinitely often}, by
\[(A_n\; \text{i.o.}) = \bigcap_{n=1}^\infty\bigcup_{i=n}^\infty A_i - \{\omega \in \Omega | \omega \; \text{belongs to infinitely many $A_n$}\}\]
\end{defn}

\begin{lem}
(Borel-Cantelli)
Let $\{A_n\}$ be a sequence of events. If $\displaystyle\sum_{n=1}^\infty \bbP\{A_n\}<\infty,$ then $\bbP\{(A_n \; \text{i.o.})\} = 0.$
\end{lem}

\begin{proof}
Since $(A_n \; \text{i.o.}) \subseteq \displaystyle\sum_{i=n}^\infty A_i,$ we have that
\[\bbP\{(A_n \; \text{i.o.})\} \leq \lim\limits_{n\to \infty}\bbP\{\bigcup_{i=n}^n A_i\}\leq \lim\limits_{n\to \infty}\sum_{i=n}^n \bbP\{A_i\},\] where, as $n\to \infty,$ we have that $\displaystyle\lim\limits_{n\to \infty}\displaystyle\sum_{i=n}^n \bbP\{A_i\}\to 0 \; (\text{a.s.}).$
\end{proof}




\subsection{The Radon-Nikodym Theorem} %all
We now introduce a tool which allows us to compare measures.  
\begin{thm}
Suppose $\mu$ and $\nu$ are measures on $(\Omega, \mathcal{F})$ such that
\[\Omega = \bigcup_{n=1}^\infty A_n, \qquad \text{with} \qquad \mu(A_n), \nu(A_n) < \infty \quad \forall n.\] Then there exists a unique $\mu-$integrable non-negative function $f$ which is measurable with respect to $\mathcal{F}$ such that for every $E\in \mathcal{F},$
\[\nu(E) = \int_E f\mathrm{d}u\]
\end{thm}

The function $f$ is called the \textit{Radon-Nikodym derivative} of $\nu$ with respect to $\mu$ and is written $\mathrm{d}\nu = f\mathrm{d}\mu$

\begin{exmp}%finbook
Let $(\Omega, \mathcal{F}, \bbP)$ be a probability space, and suppose $Q$ is a probability measure with $Q\ll P,$ then the Radon-Nikodym derivative 
\[X = \frac{\dd Q}{\dd P}\]
is a nonnegative random variable with $\bbE[X] =1$ satisfying 
\[Q(E) = \bbE_\bbP[ \textbf{1}_E X] \qquad \Leftrightarrow \qquad \dd Q(E) = \int_E X \dd \bbP.\]
\end{exmp}

\begin{defn} %bass
Suppose $(\Omega, \mathcal{F}, \bbP)$ is a probability space and $\mathcal{G}\subset \mathcal{F}.$ We define the \textit{conditional expectation} of $X$ given $\mathcal{G}$ as
\[\bbE[X | \mathcal{G}] =\frac{\dd Q}{\dd\bbP|_\mathcal{G}}\]
\end{defn}

It takes little work to show that this definition satisfies the usual definition of conditional expectation.\newline\newline
Consider a fair gambling game, where the expected winnings in the future games is $\$0,$ regardless of the games already played. Mathematically, we can express this as
\[\bbE[M_n - M_m | \mathcal{F}_m] = 0\]
This fair game is an instance of a martingale.

\begin{defn} %hardbook
Let $\bbT = \bbN.$ We say that a real-valued stochastic process $\{M_m\}_{m\in \bbT}$ is a \textit{martingale} with respect the the filtration $\{\mathcal{F}_m\}_{m\in \bbT}$:
\begin{enumerate}
    \item $\bbE[|M_m|]< \infty$ for each $n;$
    \item $\{M_m\}_{m\in \bbT}$ is adapted to $\{\mathcal{F}_m\}_{m\in \bbT};$
    \item $M_m  = \bbE[M_n | \mathcal{F}_m]$ for all $m\leq n.$
\end{enumerate}
\end{defn}

For the rest of the paper, it is assumed that $\mathcal{F}_m = \sigma(M_1, M_2, \dots, M_m).$
\begin{rem}
The definition of a \textit{continuous-time} martingale is analogous to the discrete-time martingale, with the distinction that $\bbT = [0,\infty).$
\end{rem}
The rest of the paper focuses on a specific example of a continuous-time martingale: Brownian motion.

\section{Brownian Motion}%Hardbook
We first define Brownian motion and then provide intuition for it.
\begin{defn}
A continuous adapted process $B_t$ taking values in $\bbR^d$ is called a \textit{(d-dimensional) Brownian motion} with \textit{drift m} and \textit{variance $\sigma^2$} if, for all $0 = t_0 < t_1< \cdots < t_n,$ we have that
\begin{enumerate}
\item $B_0 = 0;$
\item the distribution of $\{B_{t_{i+1}} - B_{t_i}\}_{i=1}^{n-1}$ is normal with 
\[B_{t_{i+1}} - B_{t_i} \sim N(m(t-s), \sigma^2(t-s));\]
\item $B_{t_{i+1}} - B_{t_i}$ is independent of $\mathcal{F}_{t_i}$
\end{enumerate}
\end{defn}

\subsection{Drunkard's Walk} %Finbook

To construct a continuous random motion, it is helpful to first construct the discrete case.


Let $\omega = \omega_1\omega_2\dots$ be an infinite sequence of coin tosses, where tosses happen every $\Delta t$ time increment and and $\omega_n$ is the outcome of the $n$th toss. Let
\[X_j = \begin{cases}
1, \qquad \:\:\;\omega_j = H\\
-1, \qquad \omega_j = T
\end{cases}\]
Thus, $\bbP\{X_j = 1\} = \bbP\{X_j = -1\} = \frac{1}{2}.$ Define
\[M_n:= \sum_{j=1}^nX_j\] We call the stochastic process $M_n$ a \textit{drunkard's walk} or a \textit{symmetric random walk.}


The following proposition lists the properties of the drunkard's walk which make it a great discrete-time analogy to the Brownian motion.

\begin{prop}
The drunkard's walk satisfies the following properties:
\begin{enumerate}
\item If $0 = k_0 < k_1 < \cdots < k_n$ are integers, then the random variables $\{B_{t_{i+1}} - B_{t_i}\}_{i=1}^{n-1}$ are independent with mean $0$ and variance $k_{i+1} - k_i.$
\item The drunkard's walk is a martingale.
\item The quadratic variation of the drunkard's walk is 
\[[M,M]_k = \sum_{j-1}^k(M_j - M_{j-1})^2 = k\]
\end{enumerate}
\end{prop}

\begin{proof} Recall some properties of conditional expectation.
\begin{enumerate}
    \item The first proposition is immediate by construction.
    \item Let $m<n$ be natural numbers, then using \textcolor{red}{place numbers for conditional expectation properties}
        \begin{align}
            \bbE[M_n | \mathcal{F}_m] &= \bbE[(M_n - M_m) + M_m | \mathcal{F}_m] \nonumber\\
            &= \bbE[(M_n - M_m)| \mathcal{F}_m] + \bbE[M_m | \mathcal{F}_m]\nonumber\\
            &= \bbE[(M_n - M_m)] + M_m = M_m
        \end{align}
        Where the equalities in (2.3) hold due to independence, $M_m$ being $\mathcal{F}_m$ measurable, and the first property.
    \item For any $j,$ $M_j - M_{j-1} = \pm 1,$ and thus $\displaystyle\sum_{j=1}^k (\pm 1)^2 = k.$
\end{enumerate}
\end{proof}

\begin{rem} %Shreve
We can approximate Brownian motion as a limit of the Drunkard's walk where the speed of coin tosses is increased and the step size is decreased, we  define a \textit{scaled random walk} by \[W^{(N)}_{t} = \frac{1}{\sqrt{N}}M_{Nt},\] where $N$ is a fixed integer, $N\Delta t$ is an integer and $\frac{1}{\sqrt{N}}$ is the step size of the walk. 


We prove a few properties of Proposition 2.2 and leave the rest for the reader to check: 
\begin{enumerate}
    \item While the expectation is still obviously $0,$ we need to check the variance. Let $s<t,$ then
        \[\Var[W^{(N)}_{t} - W^{(N)}_{s}] = \Var[\frac{1}{\sqrt{N}}(M_{Nt} - M_{Ns}] = \frac{1}{N}(\Var[X_1] + \Var[X_2] + \cdots + \Var[X_{t-s}]) = (t-s)\]
    \item For $t\geq 0$ such that $nt$ is an integer,
    \[[W^{(N)} W^{(N)}](t) = \sum_{j=1}^{Nt} \left[W^{(N)}\left(\frac{j}{N}\right) - W^{(N)}\left(\frac{j-1}{N}\right)\right]^2 = \sum_{j=1}^{Nt} \left[\frac{1}{\sqrt{N}}X_j\right]^2 = t\]
\end{enumerate}
Moreover, we will state, but not prove, one final theorem from \cite{Shreve} for the scaled random walk.
\begin{thm}
(\textbf{Central limit}) Let $t\geq 0.$ As $N\to \infty,$ the distribution of the scaled random walk $W^{(n)}(t)$ evaluated at time $t$ converges to the normal distribution with mean zero and variance $t.$
\end{thm}
\end{rem}

\subsection{L√©vy‚Äôs Construction of Brownian Motion}
To show that there does indeed exist a Brownian motion, we will give the L√©vy construction from \cite{SCA}, but we first need a few preliminary definitions.

%Next three are hardbook

\begin{defn}
We denote the \textit{space of measurable functions} by 
\[\mathcal{L}^0(\Omega, \mathcal{F}, \mu) = \{f: \Omega \to \bbR | f^{-1}(A) \in \mathcal{F}, A\in \mathcal{B}[0,\infty]\}.\] Where $\mathcal{B}$ denotes the Borel sets. 
\end{defn}

\begin{defn}
Let $f \in \mathcal{L}^0(\Omega, \mathcal{F}, \mu)$ and $p\in (0,\infty].$\footnote{Technically, we require a different definition for $p = \infty,$ see \cite{SCA}} We denote the \textit{$L^p$ norm of $f$} by 
\[\norm{f}_p = \left(\int |f(x)|^p d\mu \right)^\frac{1}{p}.\]
\end{defn}

\begin{defn}
For $p<\infty,$ we define $\mathcal{L}^p$
\[\mathcal{L}^p = \{f\in \mathcal{L}^0(\Omega, \mathcal{F}, \mu) | \norm{f}_p< \infty\}.\] We can then define the \textit{$L^p$ space} as the space of equivalent classes in $\mathcal{L}^p$ under the relation $f = g\; \text{a.e}.$
\end{defn}

\begin{lem} %Hardbook
Let $\{X^n\}_{n\in \bbN}$ be a sequence of a.s. continuous functions which converge unfiromly in probability to a process $X,$ that is, for any $\epsilon>0,$ 
\[\lim\limits_{n} \bbP\{\lim\sup_{s\in [0,t]} ||X_s^n - X_s||< \epsilon\} =1\] for all $t.$ Then $X$ is also continuous. 
\end{lem}
We leave this lemma without proof, but note that for fixed $\omega,$ this is just a classical uniform convergence statement. For fixed $t,$ there exists a sub-sequence in $n$ such that convergence is almost sure. 

For $n\in \bbN_0,$ define \[D_n := \{\frac{k}{2^n} | k \in \bbN\},\] $D_0 = \bbN.$ Then we have that $\mathcal{D} = \displaystyle\bigcup_n D_n$ is the set of Dyatic rations. Let $\{Z_m\}_{m\in \mathcal{D}}$ be a collection of random variables such that $Z_m \sim N(0,1),$ and $Z_0 = 0.$ Determine the value of the $n$th approximation $X_t^n$ on $t\in D_n,$ by defining
\[X_t^0 = \sum_{k\in D_0: k< t}Z_k.\] For $n>0,$ define $X_t^n = X_t^{n-1}$ for all $t\in D_{n-1}.$ For $t\in D_n\sm D_{n-1},$ let 
\begin{align}
X_t^n = X_t^{n-1} + \frac{Z_t}{2^{n+1}} 
\end{align}
and use linear interpolation to define $X_t^n$ for all value of $t.$ We can now formally interpolate between $\{X_t^n\}_{t\in D_n}:$
\[X_t^n = X^n_{\lfloor t\rfloor_n} + \frac{t - \lfloor t\rfloor_n}{\lceil t\rceil_n - \lfloor t\rfloor_n}(X^n_{\lceil t\rceil_n} - X^n_{\lfloor t\rfloor_n})\] where $\lfloor t\rfloor_n$ is the maximum $s\in D_n$ less than $t,$ and $\lceil t\rceil_n$ is defined similarly. 

\begin{thm}
The processes $X^n$ defined in (2.10) converge, in its natural filtration, a.s. uniformly to a process Brownian motion starting at zero.
\end{thm}
\begin{proof}
First we will show convergence. By construction, we have that 
\[\sup\limits_{s\in [0,t]}||X_s^n - X_s^{n+1}|| = \max\limits_{s\in \{D_{n+1}\sm D_n | s<t\}}||\frac{Z_s}{2^{(\frac{n}{2} +1)}}||.\] Note that $\{D_{n+1}\sm D_n | s<t\}$ has $t2^n$ elements. Let $F(x):=\bbP\{||Z_s||^2 \leq x\}$ be the distribution function of $||Z_s||^2,$\footnote{It is known that $||Z_s||^2$ has a $\chi^2-$distribution with $d=2,$ and thus $F(x) = 1-e^{\frac{-x}{2}}.$} then
\textcolor{red}{Ok for me to change to geq?}
\begin{align*}
\bbP\{\sup\limits_{s\in [0,t]} ||X_s^n - X_s^{n+1}||\geq\epsilon\} &= \bbP\{\max\limits_{\{D_{n+1}\sm D_n | s<t\}} ||Z_s|| \geq2^{n+1}\epsilon\}\\
&\leq \sum_{s\in \{D_{n+1}\sm D_n | s<t\}} \bbP\{||Z_s||\geq 2^{n+1}\epsilon\}\\
&= t2^n(1-F(2^{2n+2}\epsilon^2))\\
&= t2^n \exp\{-2^{2n+1}\epsilon^2.\}\\
&\leq te^{-n}<\infty
\end{align*}
Where the last inequality stands since as $n\to \infty,$ we can choose $N$ large enough such that $N\ln(2) - 2^{2N+1}\epsilon^2<-N,$ and thus the inequality hold for $n>N.$ Thus, by Borel-Cantelli (Lemma 1.10), we have that 
\[\bbP\{\sup\limits_{s\in [0,t]} ||X_s^n - X_s^{n+1}||\geq\epsilon\} \; \text{for infinitely many $n$}\}=0.\] Thus, by Lemma 2.9, we have that the processes $X^n$ converges uniformly on the interval $[0,t]$ and thus $X$ is a continuous process.

Now we need to prove that $X$ is a Brownian motion in its natural filtration. For $\lceil s\rceil_n <t,$ $t\in D_n \sm D_{n+1},$ we know that $Z_t$ is independent of $\mathcal{F}_s = \sigma(X_u | u\leq s)$ since $Z_t$ is not involved in the construction of $X_s.$ Thus,
\[X_t - X_s  = X_t^0 - X_s^0 = \sum_{k\in D_0: s<k<t} \sim N(0,(t-s))\] and $X_t - X_s$ is independent of $\mathcal{F}_s$ by the above logic. If the result holds for $s,t \in D_n,$ then for any $u\in D_{n+1}\sm D_n,$
\[X_u - X_{\lfloor u\rfloor_n} = \frac{X_{\lceil u \rceil_n}+ X_{\lfloor u \rfloor_n}}{2} + \frac{Z_u}{2^{n+2}} = \frac{2^{-(n+1)}Z_{\lceil u\rceil_n}}{2} + \frac{Z_u}{2^{n+2}}\sim N(0,\frac{1}{2^{n+1}}).\] Similarly, we have that $X_{\lceil u \lceil_n} - X_u\sim N(0,\frac{1}{2^{n+1}}).$ Both intervals are independent of $\mathcal{F}_{\lfloor u\rfloor_n}$ by the above logic. Thus, for all $s,t \in D_{n+1},$
\[X_t - X_s = (X_t - X_{\lfloor t\rfloor_n}) + (X_{\lfloor t\rfloor_n} - X_{\lceil s\rceil_n}) + (X_{\lceil s\rceil_n} - X_s)\sim N(0,(t-s)).\] The first two terms of the sum are independent of $\mathcal{F}_{\lceil s\rceil_n},$ and thus independent of $\mathcal{F}_s.$ The last is independent of both $\mathcal{F}_{\lfloor s\rfloor_n}$ and 
$X_{s} - X_{\lfloor s \rfloor_n}.$ To prove it is independent of $\mathcal{F}_s,$ simply write 
\[\mathcal{F}_s = \mathcal{F}_{\lfloor s\rfloor_n}\vee \sigma(X_s - X_{\lfloor s\rfloor_n}) \vee \sigma(Z_u | u \in (\lfloor s\rfloor_n), s)\] to see that $X_{\lceil s\rceil_n}$ is independent of $\mathcal{F}_s.$ Thus, by inducting, we see that for any $D_n \in \mathcal{D},$ if $s,t \in D_{n+1},$ we have that $X_t - X_s$ is normally distributed and independent of $\mathcal{F}_s.$

Finally, if $s<t,$ we can find sequences $s_n \downarrow s$ and $t_n \uparrow t$ with $s_n, t_n \in D_n$ and $s_k \leq t_k$ for some $k\geq 0.$ Then $X_{t_n} - X_{s_n} \sim N(0, (t_n - s_n))$ and by continuity of $X,$ we have that
\[X_t - X_s = X_{t_k} - X_{s_k} + \sum_{n = k+1}^\infty (X_{t_n} - X_{t_{n-1}} - X_{s_n} + X_{s_{n-1}})\sim N(0,(t-s)).\] Thus, $X$ is a Brownian motion starting at zero (by construction) in its natural filtration.
\end{proof}

\subsection{Brownian Motion}
Having now showed the existence of Brownian motion, we can talk about some of its properties.

\begin{thm}
Brownian motion is a martingale.
\end{thm}
While, the proof of the theorem is identical to its discrete version in Proposition 2.2, this theorem now allows us to talk about some interesting martingale properties which we can now apply to the continuous random motion.

\begin{thm}(Doob's Optional Stopping Theorem) Let $\{\mathcal{F}_n\}_{n \in \bbN}$ be a filtration on $\mathcal{F}$ and $M_n$ be a martingale with respect to $\{\mathcal{F}_n\}.$ If $T$ is a stopping time bounded above by some integer $K,$ then $\bbE[M_n] = \bbE[M_k]$
\end{thm}
We prove this in the discrete case, but the proof is analogous to the continuous case.

\begin{proof}
\end{proof}


%Nowhere differentiable


\section{Stochastic Calculus}
\subsection{The It\^{o}-Integral}
\subsection{Quadratic Variation}
\subsection{It\^{o}-Doeblin Formula}
\section{Financial Applications}
\subsection{Girsanov's Theorem}
\subsection{The Black-Scholes-Merton Equation}
\section{Appendix}
\subsection{Proof of Radon-Nikodym Theorem}

\subsection{Levy's Theorem}


\begin{thebibliography}{9}

\bibitem{Bass} 
Richard. F. Bass. 
Real Analysis for Graduate Students, Second Edition
https://bass.math.uconn.edu/v43.pdf

\bibitem{IIT}
Joydeep Dutta.
Probability and Stochastics for Finance.
Indian Institute of Technology, Kanpur.
https://www.youtube.com/@probabilityandstochasticsf5278/videos

\bibitem{Lawler}
Gregory F. Lawler.
Stochastic Calculus: An Introduction with
Applications
https://www.math.uchicago.edu/~lawler/finbook.pdf


\bibitem{SCA}
Samuel N. Cohen, Robert J. Elliot.
Stochastic Calculus and Applications, Second Edition.
Springer, 2015.

\bibitem{Shreve}
Steven E. Shreve.
Stochastic Calculus for Finance II, Continuous-Time Models.
https://files.owenoertell.com/textbooks/finance/stochCal2-shreve.pdf.

\bibitem{Doeblin}
Bru, B., Yor, M. Comments on the life and mathematical legacy of Wolfgang Doeblin. Finance Stochast 6, 3‚Äì47 (2002). https://doi.org/10.1007/s780-002-8399-0

\end{thebibliography}

\end{document}

